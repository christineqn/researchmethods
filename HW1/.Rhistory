wtpControl2 = as.numeric(as.character(temp$wtp60to60_1...353))
gainLossOnly$wtp30to30 = wtpControl1
gainLossOnly$wtp60to60 = wtpControl2
# Now, gainLossOnly also has the control trials - the trials that we want to use to actually exclude people
gainLossOnly$above50Exclusion = ifelse((gainLossOnly$wtp30to30 > .5 |
gainLossOnly$wtp60to60 > .5 ), 1, 0)
# this code above excludes people who indicated that they would pay more than $0.50 for trials in which they should
# normatively indicate that they have a WTP of $0.00
#convert everything to numeric
gainLossOnly[] = sapply(gainLossOnly, function(x) as.numeric(as.character(x)))
names(gainLossOnly)
# So, for each of the columns, we have how much the participant is WTP for the specified change in probability
gainLossOnly$id = 1:nrow(gainLossOnly) # this adds an ID variable so that we can keep track of participant
# this command changes the data to 'long' form - it makes it so that participants are now rows (not columns)
long = gather(gainLossOnly, key=questionRaw, value=wtp, loss90to80_1:loss20to10_1)
View(long) # use this command just to get a sense of what the data now look like
long$trialType = ifelse(str_detect(long$questionRaw, "gain"), "gain", "loss") # this categorizes trials as gains/losses
# the code below creates new variables that indicate the probabilities that each of the questions start/end at
long$start = gsub("[^0-9.-]", "", long$questionRaw)
long$start = substr(long$start, 1, nchar(long$start) -3)
long$startingProb = as.numeric(long$start)/100
long$endingProb = ifelse(long$trialType=='gain', long$startingProb + .1, long$startingProb - .1)
##################
#
# Data analysis
#
##################
#Plot wtp by type of change and starting probabiltiy
wtpMeans = aggregate(wtp ~ trialType + startingProb, data=long, mean)
View(wtpMeans)
require(tidyverse)
require(Hmisc)
require(ggplot2)
require(scales)
require(lme4)
require(lmerTest)
require(plyr)
require(latticeExtra)
require(stringr)
library(readxl)
fulldata <- read_excel("fulldata.xlsx")
fulldata <- read_excel("Desktop\Spring 2020\JDM\fulldata.xlsx")
fulldata <- read_excel("Desktop/Spring 2020/JDM/fulldata.xlsx")
fulldata <- read_excel("./Desktop/Spring 2020/JDM/fulldata.xlsx")
getwd()
fulldata <- read_excel("C:/Users/c1/Desktop/Spring 2020/JDM/fulldata.xlsx")
View(fulldata)
raw <- fulldata
raw = raw[6:nrow(raw), ] # this removes the headers that are not needed, as well as the preview responses
# you can tell that they are preview responses by looking at 'Status' (and you see that 'Stephen' for some responses)
temp = raw
# subset to only condition that actuall answered these question (condition 2)
temp = temp[temp$conditionOutcomesAndWTP1WTPOnly2=='2',]
names(temp)
#loss80to90_1 - this one should technically be 90 to 80, as the probability starts at 90
# so, let's rename it - it is column 362 #
names(temp)[362] <- "loss90to80_1"
ssIndxs = 362:369 # these are the questions that we actually care about for this analysis
gainLossOnly = temp[, gainLossIndxs] # let's get all of them in one place
# these are the two control trials for this condition
# one was mislabeled as r, it's really wtp 30 to 30
# check these variables names - make sure that these new variables populate with the name of the variable in temp
wtpControl1 = as.numeric(as.character(temp$r30to30_1...348))
wtpControl2 = as.numeric(as.character(temp$wtp60to60_1...353))
gainLossOnly$wtp30to30 = wtpControl1
gainLossOnly$wtp60to60 = wtpControl2
# Now, gainLossOnly also has the control trials - the trials that we want to use to actually exclude people
gainLossOnly$above50Exclusion = ifelse((gainLossOnly$wtp30to30 > .5 |
gainLossOnly$wtp60to60 > .5 ), 1, 0)
# this code above excludes people who indicated that they would pay more than $0.50 for trials in which they should
# normatively indicate that they have a WTP of $0.00
#convert everything to numeric
gainLossOnly[] = sapply(gainLossOnly, function(x) as.numeric(as.character(x)))
names(gainLossOnly)
# So, for each of the columns, we have how much the participant is WTP for the specified change in probability
gainLossOn
# So, for each of the columns, we have how much the participant is WTP for the specified change in probability
gainLossOnly$id = 1:nrow(gainLossOnly) # this adds an ID variable so that we can keep track of participant
# this command changes the data to 'long' form - it makes it so that participants are now rows (not columns)
long = gather(gainLossOnly, key=questionRaw, value=wtp, loss90to80_1:loss20to10_1)
View(long) # use this command just to get a sense of what the data now look like
library(tidyverse)
library('tidyverse')
install.packages('tidyverse')
install.packages("tidyverse")
brary(readxl)
fulldata <- read_excel("C:/Users/c1/Desktop/Spring 2020/JDM/fulldata.xlsx")
View(fulldata)
raw <- fulldata
raw = raw[6:nrow(raw), ] # this removes the headers that are not needed, as well as the preview responses
# you can tell that they are preview responses by looking at 'Status' (and you see that 'Stephen' for some responses)
temp = raw
# subset to only condition that actuall answered these question (condition 2)
temp = temp[temp$conditionOutcomesAndWTP1WTPOnly2=='2',]
names(temp)
#loss80to90_1 - this one should technically be 90 to 80, as the probability starts at 90
# so, let's rename it - it is column 362 #
names(temp)[362] <- "loss90to80_1"
#loss55to45_1
#loss40to30_1
#loss20to10_1
#gain80to90_1
#gain45to55_1
#gain10to20_1
#gain60to70_1
gainLossIndxs = 362:369 # these are the questions that we actually care about for this analysis
gainLossOnly = temp[, gainLossIndxs] # let's get all of them in one place
# these are the two control trials for this condition
# one was mislabeled as r, it's really wtp 30 to 30
# check these variables names - make sure that these new variables populate with the name of the variable in temp
wtpControl1 = as.numeric(as.character(temp$r30to30_1...348))
wtpControl2 = as.numeric(as.character(temp$wtp60to60_1...353))
gainLossOnly$wtp30to30 = wtpControl1
gainLossOnly$wtp60to60 = wtpControl2
# Now, gainLossOnly also has the control trials - the trials that we want to use to actually exclude people
gainLossOnly$above50Exclusion = ifelse((gainLossOnly$wtp30to30 > .5 |
gainLossOnly$wtp60to60 > .5 ), 1, 0)
# this code above excludes people who indicated that they would pay more than $0.50 for trials in which they should
# normatively indicate that they have a WTP of $0.00
#convert everything to numeric
gainLossOnly[] = sapply(gainLossOnly, function(x) as.numeric(as.character(x)))
names(gainLossOnly)
# So, for each of the columns, we have how much the participant is WTP for the specified change in probability
gainLossOnly$id = 1:nrow(gainLossOnly) # this adds an ID variable so that we can keep track of participant
# this command changes the data to 'long' form - it makes it so that participants are now rows (not columns)
long = gather(gainLossOnly, key=questionRaw, value=wtp, loss90to80_1:loss20to10_1)
library(dplyr)
library(dplyr2)
library(ggplot2)
library(dplyr)
install.packages("tidyverse")
library(readxl)
fulldata <- read_excel("fulldata.xlsx")
View(fulldata)
raw <- fulldata
raw = raw[6:nrow(raw), ] # this removes the headers that are not needed, as well as the preview responses
temp = raw
# subset to only condition that actuall answered these question (condition 2)
temp = temp[temp$conditionOutcomesAndWTP1WTPOnly2=='2',]
names(temp)
#loss80to90_1 - this one should technically be 90 to 80, as the probability starts at 90
# so, let's rename it - it is column 362 #
names(temp)[362] <- "loss90to80_1"
gainLossIndxs = 362:369 # these are the questions that we actually care about for this analysis
gainLossOnly = temp[, gainLossIndxs] # let's get all of them in one place
# these are the two control trials for this condition
# one was mislabeled as r, it's really wtp 30 to 30
# check these variables names - make sure that these new variables populate with the name of the variable in temp
wtpControl1 = as.numeric(as.character(temp$r30to30_1...348))
wtpControl2 = as.numeric(as.character(temp$wtp60to60_1...353))
gainLossOnly$wtp30to30 = wtpControl1
gainLossOnly$wtp60to60 = wtpControl2
gainLossOnly$above50Exclusion = ifelse((gainLossOnly$wtp30to30 > .5 |
gainLossOnly$wtp60to60 > .5 ), 1, 0)
gainLossOnly = temp[, gainLossIndxs] # let's get all of them in one place
temp = raw
# subset to only condition that actuall answered these question (condition 2)
temp = temp[temp$conditionOutcomesAndWTP1WTPOnly2=='2',]
names(temp)
raw <- fulldata
library(readxl)
fulldata <- read_excel("fulldata.xlsx")
fulldata <- read_excel("C:\Users\c1\Desktop\Spring 2020\JDM\fulldata.xlsx")
View(fulldata)
fulldata <- read_excel("c1\Desktop\Spring 2020\JDM\fulldata.xlsx")
fulldata <- read_excel("C:/Users/c1/Desktop/Spring 2020/JDM/fulldata.xlsx")
View(fulldata)
raw <- fulldata
raw = raw[6:nrow(raw), ] # this removes the headers that are not needed, as well as the preview responses
temp = raw
# subset to only condition that actuall answered these question (condition 2)
temp = temp[temp$conditionOutcomesAndWTP1WTPOnly2=='2',]
names(temp)
#loss80to90_1 - this one should technically be 90 to 80, as the probability starts at 90
# so, let's rename it - it is column 362 #
names(temp)[362] <- "loss90to80_1"
gainLossIndxs = 362:369 # these are the questions that we actually care about for this analysis
gainLossOnly = temp[, gainLossIndxs] # let's get all of them in one place
# these are the two control trials for this condition
# one was mislabeled as r, it's really wtp 30 to 30
# check these variables names - make sure that these new variables populate with the name of the variable in temp
wtpControl1 = as.numeric(as.character(temp$r30to30_1...348))
wtpControl2 = as.numeric(as.character(temp$wtp60to60_1...353))
gainLossOnly$wtp30to30 = wtpControl1
gainLossOnly$wtp60to60 = wtpControl2
gainLossOnly$above50Exclusion = ifelse((gainLossOnly$wtp30to30 > .5 |
gainLossOnly$wtp60to60 > .5 ), 1, 0)
#convert everything to numeric
gainLossOnly[] = sapply(gainLossOnly, function(x) as.numeric(as.character(x)))
names(gainLossOnly)
# So, for each of the columns, we have how much the participant is WTP for the specified change in probability
gainLossOnly$id = 1:nrow(gainLossOnly) # this adds an ID variable so that we can keep track of participant
# this command changes the data to 'long' form - it makes it so that participants are now rows (not columns)
long = gather(gainLossOnly, key=questionRaw, value=wtp, loss90to80_1:loss20to10_1)
install.packages(tidyr)
"tidyr"
library(tidyr)
# this command changes the data to 'long' form - it makes it so that participants are now rows (not columns)
long = gather(gainLossOnly, key=questionRaw, value=wtp, loss90to80_1:loss20to10_1)
View(long) # use this command just to get a sense of what the data now look like
long$trialType = ifelse(str_detect(long$questionRaw, "gain"), "gain", "loss") # this categorizes trials as gains/losses
library(stringr)
long$trialType = ifelse(str_detect(long$questionRaw, "gain"), "gain", "loss") # this categorizes trials as gains/losses
long$trialType = ifelse(str_detect(long$questionRaw, "gain"), "gain", "loss") # this categorizes trials as gains/losses
# the code below creates new variables that indicate the probabilities that each of the questions start/end at
long$start = gsub("[^0-9.-]", "", long$questionRaw)
long$start = substr(long$start, 1, nchar(long$start) -3)
long$startingProb = as.numeric(long$start)/100
long$endingProb = ifelse(long$trialType=='gain', long$startingProb + .1, long$startingProb - .1)
wtpMeans = aggregate(wtp ~ trialType + startingProb, data=long, mean)
View(wtpMeans)
loss90to80_gain10to20 = long[long$questionRaw %in% c('loss90to80_', 'gain10to20_1')]
loss90to80_gain10to20 = long[long$questionRaw %in% c('loss90to80_', 'gain10to20_1'),]
loss55to45_gain45to55 = long[long$questionRaw %in% c('loss55to45_', 'gain45to55_1'),]
loss40to30_gain60to70 = long[long$questionRaw %in% c('loss40to30_', 'gain60to70_1'),]
loss20to10_gain80to90 = long[long$questionRaw %in% c('loss20to10_', 'gain80to90_1'),]
View(loss90to80_gain10to20)
str(loss90to80_gain10to20)
loss90to80_gain10to20 = long[long$questionRaw %in% c('loss90to80_1', 'gain10to20_1'),]
loss55to45_gain45to55 = long[long$questionRaw %in% c('loss55to45_1', 'gain45to55_1'),]
loss40to30_gain60to70 = long[long$questionRaw %in% c('loss40to30_1', 'gain60to70_1'),]
loss20to10_gain80to90 = long[long$questionRaw %in% c('loss20to10_1', 'gain80to90_1'),]
str(loss90to80_gain10to20)
View(loss90to80_gain10to20)
t.test(questionRaw ~ wtp, loss90to80_gain10to20)
t.test(loss90to80_gain10to20$questionRaw ~ loss90to80_gain10to20$wtp)
t.test(wtp ~ questionRaw, loss90to80_gain10to20)
t.test(wtp ~ questionRaw, loss55to45_gain45to55)
t.test(wtp ~ questionRaw, loss40to30_gain60to70)
t.test(wtp ~ questionRaw, loss20to10_gain80to90)
View(long)
barplot(wtpMeans[,3])
ggplot(long[long$questionRaw == 'loss90to80_1',], aes(wtp) + geom_histogram()
'gain10to20_1'),]
ggplot(long[long$questionRaw == 'loss90to80_1',], aes(wtp)) + geom_histogram()
library(ggplot2)
ggplot(long[long$questionRaw == 'loss90to80_1',], aes(wtp)) + geom_histogram()
ggplot(long[long$questionRaw == 'loss90to80_1',], aes(wtp)) + geom_histogram() + geom_smooth()
wtpMeans2 = aggregate(wtp ~ questionRaw + startingProb, data=long, FUN=mean)
ggplot(wtpMeans2, aes(x=questionRaw, y=wtp)) +
geom_bar(stat = "identity")
p = ggplot(long[long$questionRaw == 'loss90to80_1',], aes(wtp)) + geom_histogram()
p%+%geom_vline(aes(xintercept = mean(speed)),col='red',size=2)
p%+%geom_vline(aes(xintercept = mean(wtpMeans[8,3])),col='red',size=2)
p%+%geom_vline(aes(xintercept = wtpMeans[8,3]),col='red',size=2)
loss80plot = ggplot(long[long$questionRaw == 'loss90to80_1',], aes(wtp)) + geom_histogram() + geom_vline(aes(xintercept = wtpMeans[8,3]),col='red',size=2)
loss90plot = ggplot(long[long$questionRaw == 'loss90to80_1',], aes(wtp)) + geom_histogram() + geom_vline(aes(xintercept = wtpMeans[8,3]),col='red',size=2)
loss90plot
loss55plot = ggplot(long[long$questionRaw == 'loss55to45_1',], aes(wtp)) + geom_histogram() + geom_vline(aes(xintercept = wtpMeans[5,3]),col='red',size=2)
loss55plot
loss40plot = ggplot(long[long$questionRaw == 'loss40to30_1',], aes(wtp)) + geom_histogram() + geom_vline(aes(xintercept = wtpMeans[3,3]),col='red',size=2)
loss40plot
loss20plot = ggplot(long[long$questionRaw == 'loss20to10_1',], aes(wtp)) + geom_histogram() + geom_vline(aes(xintercept = wtpMeans[2,3]),col='red',size=2)
loss20plot
gain10plot = ggplot(long[long$questionRaw == 'gain10to20_1',], aes(wtp)) + geom_histogram() + geom_vline(aes(xintercept = wtpMeans[1,3]),col='red',size=2)
gain10plot
gain45plot = ggplot(long[long$questionRaw == 'gain45to55_1',], aes(wtp)) + geom_histogram() + geom_vline(aes(xintercept = wtpMeans[4,3]),col='red',size=2)
gain45plot
gain60plot = ggplot(long[long$questionRaw == 'gain60to70_1',], aes(wtp)) + geom_histogram() + geom_vline(aes(xintercept = wtpMeans[6,3]),col='red',size=2)
gain60plot
gain80plot = ggplot(long[long$questionRaw == 'gain80to90_1',], aes(wtp)) + geom_histogram() + geom_vline(aes(xintercept = wtpMeans[7,3]),col='red',size=2)
gain80plot
install.packages(tinyr)
install.packages('tinyr')
install.packages('tinyverse')
# this command changes the data to 'long' form - it makes it so that participants are now rows (not columns)
long = gather(gainLossOnly, key=questionRaw, value=wtp, loss90to80_1:loss20to10_1)
library(readxl)
install.packages("tidyverse")
library(tidyr)
library(readxl)
fulldata <- read_excel("C:/Users/c1/Desktop/Spring 2020/JDM/fulldata.xlsx")
View(fulldata)
raw <- fulldata
raw = raw[6:nrow(raw), ] # this removes the headers that are not needed, as well as the preview responses
temp = raw
# subset to only condition that actuall answered these question (condition 2)
temp = temp[temp$conditionOutcomesAndWTP1WTPOnly2=='2',]
#loss80to90_1 - this one should technically be 90 to 80, as the probability starts at 90
# so, let's rename it - it is column 362 #
names(temp)[362] <- "loss90to80_1"
gainLossIndxs = 362:369 # these are the questions that we actually care about for this analysis
gainLossOnly = temp[, gainLossIndxs] # let's get all of them in one place
# these are the two control trials for this condition
# one was mislabeled as r, it's really wtp 30 to 30
# check these variables names - make sure that these new variables populate with the name of the variable in temp
wtpControl1 = as.numeric(as.character(temp$r30to30_1...348))
wtpControl2 = as.numeric(as.character(temp$wtp60to60_1...353))
gainLossOnly$wtp30to30 = wtpControl1
gainLossOnly$wtp60to60 = wtpControl2
gainLossOnly$above50Exclusion = ifelse((gainLossOnly$wtp30to30 > .5 |
gainLossOnly$wtp60to60 > .5 ), 1, 0)
#convert everything to numeric
gainLossOnly[] = sapply(gainLossOnly, function(x) as.numeric(as.character(x)))
# So, for each of the columns, we have how much the participant is WTP for the specified change in probability
gainLossOnly$id = 1:nrow(gainLossOnly) # this adds an ID variable so that we can keep track of participant
library(tidyr)
# this command changes the data to 'long' form - it makes it so that participants are now rows (not columns)
long = gather(gainLossOnly, key=questionRaw, value=wtp, loss90to80_1:loss20to10_1)
library(stringr)
long$trialType = ifelse(str_detect(long$questionRaw, "gain"), "gain", "loss") # this categorizes trials as gains/losses
# the code below creates new variables that indicate the probabilities that each of the questions start/end at
long$start = gsub("[^0-9.-]", "", long$questionRaw)
long$start = substr(long$start, 1, nchar(long$start) -3)
long$startingProb = as.numeric(long$start)/100
long$endingProb = ifelse(long$trialType=='gain', long$startingProb + .1, long$startingProb - .1)
wtpMeans = aggregate(wtp ~ trialType + startingProb, data=long, mean)
View(wtpMeans)
loss90to80_gain10to20 = long[long$questionRaw %in% c('loss90to80_1', 'gain10to20_1'),]
loss55to45_gain45to55 = long[long$questionRaw %in% c('loss55to45_1', 'gain45to55_1'),]
loss40to30_gain60to70 = long[long$questionRaw %in% c('loss40to30_1', 'gain60to70_1'),]
loss20to10_gain80to90 = long[long$questionRaw %in% c('loss20to10_1', 'gain80to90_1'),]
t.test(wtp ~ questionRaw, loss90to80_gain10to20)
t.test(wtp ~ questionRaw, loss55to45_gain45to55)
t.test(wtp ~ questionRaw, loss40to30_gain60to70)
t.test(wtp ~ questionRaw, loss20to10_gain80to90)
library(ggplot2)
wtpMeans2 = aggregate(wtp ~ questionRaw + startingProb, data=long, FUN=mean)
means8groups = ggplot(wtpMeans2, aes(x=questionRaw, y=wtp)) + geom_bar(stat = "identity")
means8groups
loss90plot = ggplot(long[long$questionRaw == 'loss90to80_1',], aes(wtp)) + geom_histogram() + geom_vline(aes(xintercept = wtpMeans[8,3]),col='red',size=2)
loss90plot
ggplot(long[long$questionRaw == 'loss90to80_1',], aes(wtp)) + geom_histogram() + geom_vline(aes(xintercept = wtpMeans[8,3]),col='red',size=2) + labs(title='loss90plot')
require(lme4)
require(tidyverse)
source('C:/Users/c1/Desktop/Spring 2020/JDM/analysis for loss-gain trials with t-tests and plots.R')
warnings()
View(loss90to80_gain10to20)
t.test(wtp ~ questionRaw, loss90to80_gain10to20, paired=TRUE)
t.test(wtp ~ questionRaw, loss55to45_gain45to55)
t.test(wtp ~ questionRaw, loss90to80_gain10to20, paired=TRUE)
t.test(long[long$questionRaw=='loss90to80_1'], long[long$questionRaw=='loss10to20_1'], paired=TRUE)
t.test(long[long$questionRaw=='loss90to80_1',], long[long$questionRaw=='loss10to20_1',], paired=TRUE)
t.test(wtp ~ questionRaw, loss55to45_gain45to55, paired=TRUE)
t.test(wtp ~ questionRaw, loss40to30_gain60to70, paired=TRUE)
t.test(wtp ~ questionRaw, loss20to10_gain80to90, paired=TRUE)
table(loss90to80_gain10to20$questionRaw)
p <- loss90to80_gain10to20 %>%
filter(duplicated(id) | duplicated(id, fromLast=TRUE)) %>%
arrange(questionRaw, id)
View(p)
t.test(wtp ~ questionRaw, loss90to80_gain10to20, paired=TRUE, na.action)
t.test(wtp ~ questionRaw, loss55to45_gain45to55, paired=TRUE)
table(loss55to45_gain45to55$questionRaw)
sumRows(is.na(loss90to80_gain10to20))
rowSums(is.na(loss90to80_gain10to20))
options("na.action")
t.test(wtp ~ questionRaw, loss90to80_gain10to20, paired=TRUE, na.exclude)
t.test(wtp ~ questionRaw, loss55to45_gain45to55, paired=TRUE, na.action="exclude")
t.test(wtp ~ questionRaw, loss55to45_gain45to55, paired=TRUE, na.action="na.exclude")
t.test(wtp ~ questionRaw, loss55to45_gain45to55, paired=TRUE, na.action=getOption("na.exclude"))
t.test(wtp ~ questionRaw, loss90to80_gain10to20, paired=TRUE, na.action=getOption("na.exclude"))
t.test(wtp ~ questionRaw, loss55to45_gain45to55, paired=TRUE, na.action=getOption("na.exclude"))
t.test(wtp ~ questionRaw, loss40to30_gain60to70, paired=TRUE, na.action=getOption("na.exclude"))
t.test(wtp ~ questionRaw, loss20to10_gain80to90, paired=TRUE, na.action=getOption("na.exclude"))
####Set up####
###packages
library(MASS)
library(ggplot2)
library(pscl)
library(plyr)
library(doBy)
library(lme4)
library(lmerTest)
install.packages ('doBy')
#Check where working directory is currently set
getwd()
65
## Numeric and Integer Objects-
Ht <- c(65, 70)
Ht2 <- c(Ht, 64.5) #Assign heights from Ht plus new height of 65 to Ht2
## Character and Factor Objects----
Gnd <- c("woman","man","woman", NA) #Assign genders for three individuals
Gnd2 <- factor(Gnd) #Convert character object to factor
#Vectors vs Lists
#Combine objects using c - Objects will be coerced to be same type
dataList <- c(Gnd2, Ht2)
dataList
class(dataList)
#Combine objects using list - Objects retain original types
dataList2 <- list(Gnd2, Ht2)
dataList2
class(dataList2)
class(dataList2[[2]])
setwd('C:/Users/c1/OneDrive/Desktop/Fall 2021/Research methods II/model assignment')
library('stargazer')
library('stargazer')
library('sjPlot')
# Read in data:
# insheet using Ai-Experiment-Data.csv, comma names clear
ai_data <- read.csv('Ai-Experiment-Data.csv')
# Store regression
# eststo regression_one
regression_one <- lm(Recommends.Ai.Adoption ~ ReadEthicsArticle, ai_data)
stargazer(regression_one, type='text', omit.stat=c('LL','ser','f'), no.space=T, intercept.bottom=F, notes='Standard errors in parentheses.')
tab_model(regression_one, collapse.se=T, show.ci=F, p.style='stars')
?tab_model
tab_model(regression_one, out='Ai-Experiment-Table-sjplot.doc', collapse.se=T, show.ci=F, p.style='stars')
tab_model(regression_one, file='Ai-Experiment-Table-sjplot.doc', collapse.se=T, show.ci=F, p.style='stars')
stargazer(regression_one, type='text', omit.stat=c('LL','ser','f'), no.space=T, intercept.bottom=F, digit.separator='', notes='Standard errors in parentheses.')
stargazer(regression_one, type='text', omit.stat=c('LL','ser','f'), no.space=T, intercept.bottom=F, digit.separator='', initial.zero=F, notes='Standard errors in parentheses.')
stargazer(regression_one, type='text', omit.stat=c('LL','ser','f'), digit.separator='', initial.zero=F, intercept.bottom=F, no.space=T, omit.table.layout='l', notes='Standard errors in parentheses.')
star_doc <- stargazer(regression_one, type='text', omit.stat=c('LL','ser','f'), digit.separator='', initial.zero=F, intercept.bottom=F, no.space=T, omit.table.layout='l', notes='Standard errors in parentheses.')
stargazer(star_doc, out='Ai-Experiment-Table-stargazer.doc')
stargazer(regression_one, type='html', omit.stat=c('LL','ser','f'), digit.separator='', initial.zero=F, intercept.bottom=F, no.space=T, omit.table.layout='l', notes='Standard errors in parentheses.', out='Ai-Experiment-Table-stargazer.doc')
stargazer(regression_one, type='html', omit.stat=c('LL','ser','f'), digit.separator='', initial.zero=F, intercept.bottom=F, no.space=T, omit.table.layout='l', notes='Standard errors in parentheses.', out='Ai-Experiment-Table-stargazer.doc')
stargazer(regression_one, style='asq')
stargazer(regression_one, style='asq', type='text')
stargazer(regression_one, style='aer', type='text')
stargazer(regression_one, style='ajs', type='text')
stargazer(regression_one, style='asr', type='text')
stargazer(regression_one, style='ajps', type='text')
stargazer(regression_one, style='apsr', type='text')
stargazer(regression_one, style='demography', type='text')
stargazer(regression_one, style='io', type='text')
stargazer(regression_one, style='jpam', type='text')
stargazer(regression_one, style='qje', type='text')
##################################
# FOR PEOPLE USING MICROSOFT:
# global tableoptions "bf(%15.2gc) sfmt(%15.2gc) se label noisily noeqlines nonumbers varlabels(_cons Constant, end("" ) nolast)  starlevels(# 0.1 ## 0.05 ### 0.01) replace r2"
# esttab regression_one using Ai-Experiment-Table.rtf, $tableoptions keep(readethicsarticle)
stargazer(regression_one, type='text', omit.stat=c('LL','ser','f'), digit.separator='', initial.zero=F, intercept.bottom=F, no.space=T, omit.table.layout='l', notes='Standard errors in parentheses.')
##################################
# FOR PEOPLE USING MICROSOFT:
# global tableoptions "bf(%15.2gc) sfmt(%15.2gc) se label noisily noeqlines nonumbers varlabels(_cons Constant, end("" ) nolast)  starlevels(# 0.1 ## 0.05 ### 0.01) replace r2"
# esttab regression_one using Ai-Experiment-Table.rtf, $tableoptions keep(readethicsarticle)
stargazer(regression_one, type='text', dep.var.cap='', omit.stat=c('LL','ser','f'), digit.separator='', initial.zero=F, intercept.bottom=F, no.space=T, notes='Standard errors in parentheses.')
##################################
# FOR PEOPLE USING MICROSOFT:
# global tableoptions "bf(%15.2gc) sfmt(%15.2gc) se label noisily noeqlines nonumbers varlabels(_cons Constant, end("" ) nolast)  starlevels(# 0.1 ## 0.05 ### 0.01) replace r2"
# esttab regression_one using Ai-Experiment-Table.rtf, $tableoptions keep(readethicsarticle)
stargazer(regression_one, type='text', dep.var.cap='', omit.stat=c('LL','ser','f'), digit.separator='', initial.zero=F, intercept.bottom=F, no.space=T, notes='Standard errors in parentheses.')
##################################
# FOR PEOPLE USING MICROSOFT:
# global tableoptions "bf(%15.2gc) sfmt(%15.2gc) se label noisily noeqlines nonumbers varlabels(_cons Constant, end("" ) nolast)  starlevels(# 0.1 ## 0.05 ### 0.01) replace r2"
# esttab regression_one using Ai-Experiment-Table.rtf, $tableoptions keep(readethicsarticle)
stargazer(regression_one, type='text', dep.var.caption='', omit.stat=c('LL','ser','f'), digit.separator='', initial.zero=F, intercept.bottom=F, no.space=T, notes='Standard errors in parentheses.')
##################################
# FOR PEOPLE USING MICROSOFT:
# global tableoptions "bf(%15.2gc) sfmt(%15.2gc) se label noisily noeqlines nonumbers varlabels(_cons Constant, end("" ) nolast)  starlevels(# 0.1 ## 0.05 ### 0.01) replace r2"
# esttab regression_one using Ai-Experiment-Table.rtf, $tableoptions keep(readethicsarticle)
stargazer(regression_one, type='text', dep.var.caption='', omit.stat=c('LL','ser','f'), digit.separator='', digits=2, initial.zero=F, intercept.bottom=F, no.space=T, notes='Standard errors in parentheses.')
stargazer(regression_one, type='html', dep.var.caption='', omit.stat=c('LL','ser','f'), digit.separator='', digits=2, initial.zero=F, intercept.bottom=F, no.space=T, notes='Standard errors in parentheses.', out='Ai-Experiment-Table-stargazer.doc')
setwd("C:/Users/c1/OneDrive/Desktop/Fall 2021/Research methods II/researchmethods/HW1")
library('stargazer')
# Read in data:
data <- read.csv('assignment1-research-methods.csv')
View(data)
names(data)
# Run regression:
# effect of having an elite college on whether the fictitious candidate's job application was called back
regression <- lm(calledback ~ EliteSchoolCandidate, data)
# Run regression:
# effect of having an elite college on whether the fictitious candidate's job application was called back
regression <- lm(calledback ~ EliteSchoolCandidate, data)
# Output:
stargazer(regression, type='text', dep.var.caption='', omit.stat=c('LL','ser','f'), digit.separator='', digits=2, initial.zero=F, intercept.bottom=F, no.space=T, notes='Standard errors in parentheses.')
regression2 <- lm(calledback ~ EliteSchoolCandidate*MaleCandidate, data)
regression4 <- lm(calledback ~ EliteSchoolCandidate +
recruiteriswhite + recruiterismale +
MaleCandidate + EliteSchoolCandidate, data)
stargazer(regression, type='text', dep.var.caption='', omit.stat=c('LL','ser','f'), digit.separator='', digits=2, initial.zero=F, intercept.bottom=F, no.space=T, notes='Standard errors in parentheses.')
# Run regression:
# effect of having an elite college on whether the fictitious candidate's job application was called back
regression <- lm(calledback ~ EliteSchoolCandidate, data)
regression2 <- lm(calledback ~ EliteSchoolCandidate*MaleCandidate, data)
regression3 <- lm(calledback ~ EliteSchoolCandidate*BigCompanyCandidate, data)
regression4 <- lm(calledback ~ EliteSchoolCandidate*recruiteriswhite, data)
regression5 <- lm(calledback ~ EliteSchoolCandidate +
recruiteriswhite + recruiterismale +
MaleCandidate + EliteSchoolCandidate, data)
stargazer(regression, regression2, regression3, regression4, regression5, type='text', dep.var.caption='', omit.stat=c('LL','ser','f'), digit.separator='', digits=2, initial.zero=F, intercept.bottom=F, no.space=T, notes='Standard errors in parentheses.')
stargazer(regression, regression2, regression3, regression4, regression5,
type='html', dep.var.caption='', omit.stat=c('LL','ser','f'), digit.separator='', digits=2, initial.zero=F, intercept.bottom=F, no.space=T, notes='Standard errors in parentheses.',
out='hw1-table2.doc')
regression5 <- lm(calledback ~ EliteSchoolCandidate +
recruiteriswhite + recruiterismale +
MaleCandidate + BigCompanyCandidate, data)
stargazer(regression, regression2, regression3, regression4, regression5,
type='html', dep.var.caption='', omit.stat=c('LL','ser','f'), digit.separator='', digits=2, initial.zero=F, intercept.bottom=F, no.space=T, notes='Standard errors in parentheses.',
out='hw1-table.doc')
library('dplyr')
names(ai_data)
names(data)
# Label your variables
data <- rename(data,
CandidateID=candidateid,
CalledBack=calledback,
RecruiterIsWhite=recruiteriswhite,
RecruiterIsMale=recruiterismale)
# effect of having an elite college on whether the fictitious candidate's job application was called back
regression <- lm(calledback ~ EliteSchoolCandidate, data)
regression2 <- lm(calledback ~ EliteSchoolCandidate*MaleCandidate, data)
regression3 <- lm(calledback ~ EliteSchoolCandidate*BigCompanyCandidate, data)
regression4 <- lm(calledback ~ EliteSchoolCandidate*RecruiterIsWhite, data)
regression5 <- lm(calledback ~ EliteSchoolCandidate +
RecruiterIsWhite + recruiterismale +
MaleCandidate + BigCompanyCandidate, data)
# Output:
regression <- lm(CalledBack ~ EliteSchoolCandidate, data)
regression2 <- lm(CalledBack ~ EliteSchoolCandidate*MaleCandidate, data)
regression3 <- lm(CalledBack ~ EliteSchoolCandidate*BigCompanyCandidate, data)
regression4 <- lm(CalledBack ~ EliteSchoolCandidate*RecruiterIsWhite, data)
regression5 <- lm(CalledBack ~ EliteSchoolCandidate +
RecruiterIsWhite + recruiterismale +
MaleCandidate + BigCompanyCandidate, data)
regression5 <- lm(CalledBack ~ EliteSchoolCandidate +
RecruiterIsWhite + RecruiterIsMale +
MaleCandidate + BigCompanyCandidate, data)
stargazer(regression, regression2, regression3, regression4, regression5,
type='html', dep.var.caption='', omit.stat=c('LL','ser','f'), digit.separator='', digits=2, initial.zero=F, intercept.bottom=F, no.space=T, notes='Standard errors in parentheses.',
out='hw1-table.doc')
